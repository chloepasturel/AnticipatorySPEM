{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WELCOME\n",
      "\n",
      "2020-03-04T09:27:19+01:00\n",
      "\n",
      "CPython 3.5.2\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.16.3\n",
      "matplotlib 3.0.3\n",
      "torch 1.1.0\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.4.0-83-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "host name  : INV-OPE-HP01\n",
      "Git hash   : 103f27fc49339778754a047a01bd9042b286b058\n",
      "Git repo   : https://github.com/chloepasturel/AnticipatorySPEM.git\n",
      "Git branch : master\n"
     ]
    }
   ],
   "source": [
    "%run 0_parameters.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import bayesianchangepoint as bcp"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T14:09:02.644736Z",
     "start_time": "2018-07-13T14:09:02.600752Z"
    }
   },
   "outputs": [],
   "source": [
    "msfigpath = '../PasturelMontagniniPerrinet2019/figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aSPEM import Analysis\n",
    "e = Analysis(name_file_fit='fct_velocity_sigmo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_(p, data) :\n",
    "    \n",
    "    p = np.ma.masked_array(p, mask=np.isnan(data)).compressed()\n",
    "    data = np.ma.masked_array(data, mask=np.isnan(data)).compressed()\n",
    "\n",
    "    from scipy import stats\n",
    "    slope, intercept, r_, p_value, std_err = stats.linregress(p, data)\n",
    "    \n",
    "    return r_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(p, data, bin_p=5, sub_data=40):\n",
    "    \n",
    "    x = np.ma.masked_array(p, mask=np.isnan(data)).compressed()\n",
    "    y = np.ma.masked_array(data, mask=np.isnan(data)).compressed()\n",
    "\n",
    "    support_x = np.linspace(min(x), max(x), bin_p)\n",
    "    support_y = np.linspace(min(y), max(y), int(len(data)/sub_data))\n",
    "\n",
    "    summation = 0.00\n",
    "    for a in range(len(support_x)-1):\n",
    "        for b in range(len(support_y)-1):\n",
    "            ind_x = np.where((x>=support_x[a]) & (x<=support_x[a+1]))[0]\n",
    "            ind_y = np.where((y>=support_y[b]) & (y<=support_y[b+1]))[0]\n",
    "\n",
    "            px = len(ind_x) / len(x)\n",
    "            py = len(ind_y) / len(x)\n",
    "            pxy = len(np.where(np.in1d(ind_x, ind_y)==True)[0]) / len(x)\n",
    "\n",
    "            if pxy>0.00: summation += pxy * np.log2(pxy / (px*py))\n",
    "\n",
    "\n",
    "    return summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Find_h(VA, BET, SUJETS, regress, decoupe=False) :\n",
    "    Full = e.Full_list(modes_bcp=[])\n",
    "    modes_bcp = 'mean'\n",
    "    tau = np.arange(1, 10001, 1)\n",
    "    list_h = 1/tau\n",
    "\n",
    "    r_va, r_bet = {}, {}\n",
    "    for num, s in enumerate(SUJETS) :\n",
    "\n",
    "        print(s, end=' ')\n",
    "        \n",
    "        if np.shape(BET[s])==(3, 200) :\n",
    "            bet = []\n",
    "            for b in range(3) : bet.extend(BET[s][b])\n",
    "        else : bet = BET[s]\n",
    "            \n",
    "            \n",
    "        if np.shape(VA[s])==(3, 200) :\n",
    "            va = []\n",
    "            for b in range(3) : va.extend(VA[s][b])\n",
    "        else : va = VA[s]\n",
    "        \n",
    "        x = np.array(Full['bino'][Full.sujet==s].values.tolist())\n",
    "\n",
    "        r_va[s], r_bet[s] = [], []\n",
    "        if decoupe=='block' :\n",
    "            for c in range(0, 3*200-150, 50) : r_va[s].append([]) ; r_bet[s].append([])\n",
    "\n",
    "        for h in list_h :\n",
    "\n",
    "            if decoupe is False : p_hat_suj = np.zeros(600)\n",
    "            \n",
    "            for d, c in enumerate(range(0, 3*200-150, 200)) :\n",
    "                x_200 = x[c:c+200]\n",
    "                p_hat_200 = np.zeros(200)\n",
    "\n",
    "                liste = [0, 50, 100, 150, 200]\n",
    "                for a in range(len(liste)-1) :\n",
    "                    p_bar, r_bar, beliefs = bcp.inference(x_200[liste[a]:liste[a+1]], h=h, p0=.5, r0=1.)\n",
    "                    p_hat_p, r_hat = bcp.readout(p_bar, r_bar, beliefs, mode=modes_bcp, p0=.5, fixed_window_size=40)\n",
    "                    p_hat_200[liste[a]:liste[a+1]] = p_hat_p\n",
    "                \n",
    "                if decoupe=='block' :\n",
    "                    if regress=='r' :\n",
    "                        r_va[s][d].append(r_(p_hat_200.tolist(), va[c:c+200]))\n",
    "                        r_bet[s][d].append(r_(p_hat_200.tolist(), bet[c:c+200]))\n",
    "                    elif regress=='MI' :\n",
    "                        r_va[s][d].append(mutual_information(p_hat_200.tolist(), va[c:c+200]))\n",
    "                        r_bet[s][d].append(mutual_information(p_hat_200.tolist(), bet[c:c+200]))\n",
    "\n",
    "                if decoupe is False : p_hat_suj[c:c+200] = p_hat_200\n",
    "             \n",
    "            if decoupe is False :\n",
    "                if regress=='r' :\n",
    "                    r_va[s].append(r_(p_hat_suj.tolist(), va))\n",
    "                    r_bet[s].append(r_(p_hat_suj.tolist(), bet))\n",
    "                elif regress=='MI' :\n",
    "                    r_va[s].append(mutual_information(p_hat_suj.tolist(), va))\n",
    "                    r_bet[s].append(mutual_information(p_hat_suj.tolist(), bet))\n",
    "                    \n",
    "                \n",
    "    recording = {}\n",
    "    recording['list_h'] = list_h\n",
    "    recording['list_tau'] = tau\n",
    "    recording['r_va'] = r_va\n",
    "    recording['r_bet'] = r_bet\n",
    "    \n",
    "    return recording"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Full = e.Full_list(modes_bcp=[])\n",
    "\n",
    "sujet = list(np.sort(list(set(Full.sujet))))\n",
    "BET, VA = {}, {}\n",
    "for s in sujet :\n",
    "    BET[s] = Full['results'][Full.sujet==s].values.tolist()\n",
    "    VA[s] = Full['va'][Full.sujet==s].values.tolist()\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "'''d = False\n",
    "#fname, recording = 'list_h_sujet.pkl', Find_h(VA, BET, sujet, regress='r', decoupe=d)\n",
    "fname, recording = 'list_h_MI_sujet.pkl', Find_h(VA, BET, sujet, regress='MI', decoupe=d) \n",
    "'''\n",
    "\n",
    "d = 'block'\n",
    "#fname, recording = 'list_h_block.pkl', Find_h(VA, BET, sujet, regress='r', decoupe=d)\n",
    "fname, recording = 'list_h_MI_block.pkl', Find_h(VA, BET, sujet, regress='MI', decoupe=d) \n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "file = os.path.join('parametre/list_h', fname)\n",
    "with open(file, 'wb') as fichier:\n",
    "    f = pickle.Pickler(fichier)\n",
    "    f.dump(recording)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "data_scalling = e.Data_Scalling()\n",
    "file = os.path.join('parametre', 'Data_Scaling.pkl')\n",
    "with open(file, 'wb') as fichier:\n",
    "    f = pickle.Pickler(fichier)\n",
    "    f.dump(data_scalling)\n",
    "'''\n",
    "\n",
    "file = os.path.join('parametre', 'Data_Scaling.pkl')\n",
    "with open(file, 'rb') as fichier:\n",
    "    new_data = pickle.load(fichier, encoding='latin1')\n",
    "Full = e.Full_list(modes_bcp=[])\n",
    "sujet = list(np.sort(list(set(Full.sujet))))\n",
    "\n",
    "va_suj, bet_suj = new_data['new_va_sujet'], new_data['new_bet_sujet']\n",
    "va_full, bet_full = new_data['new_va_full'], new_data['new_bet_full']\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "d = False\n",
    "f, r = 'list_h_sujet_Scalling_sujet.pkl', Find_h(va_suj, bet_suj, sujet, regress='r', decoupe=d) \n",
    "f1, r1 = 'list_h_sujet_Scalling_full.pkl',  Find_h(va_full, bet_full, sujet, regress='r', decoupe=d) \n",
    "\n",
    "#f, r = 'list_h_MI_sujet_Scalling_sujet.pkl', Find_h(va_suj, bet_suj, sujet, regress='MI', decoupe=d)\n",
    "#f1, r1 = 'list_h_MI_sujet_Scalling_full.pkl', Find_h(va_full, bet_full, sujet, regress='MI', decoupe=d)\n",
    "\n",
    "'''\n",
    "d = 'block'\n",
    "f, r = 'list_h_block_Scalling_sujet.pkl', Find_h(va_suj, bet_suj, sujet, regress='r', decoupe=d) \n",
    "f1, r1 = 'list_h_block_Scalling_full.pkl',  Find_h(va_full, bet_full, sujet, regress='r', decoupe=d) \n",
    "\n",
    "#f, r = 'list_h_MI_block_Scalling_sujet.pkl', Find_h(va_suj, bet_suj, sujet, regress='MI', decoupe=d)\n",
    "#f1, r1 = 'list_h_MI_block_Scalling_full.pkl', Find_h(va_full, bet_full, sujet, regress='MI', decoupe=d)\n",
    "\n",
    "'''\n",
    "\n",
    "#----------------------------------------------------------------------------------------\n",
    "\n",
    "for fname, recording in zip([f, f1], [r, r1]) :\n",
    "    file = os.path.join('parametre/list_h', fname)\n",
    "    with open(file, 'wb') as fichier:\n",
    "        f = pickle.Pickler(fichier)\n",
    "        f.dump(recording)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Full = e.Full_list(modes_bcp=[])\n",
    "modes_bcp = 'mean'\n",
    "#list_h = np.geomspace(0.0025, 0.25, 1000)# 21)\n",
    "#list_h = np.geomspace(0.001, 0.5, 100)# 21)\n",
    "tau = np.arange(1, 601, 1)\n",
    "list_h = 1/tau\n",
    "\n",
    "r_va, r_bet = {}, {}\n",
    "for num, s in enumerate(set(Full.sujet)) :\n",
    "    \n",
    "    print(s, end=' ')\n",
    "    va = Full['va'][Full.sujet==s].values.tolist()\n",
    "    bet = Full['results'][Full.sujet==s].values.tolist()\n",
    "    x = np.array(Full['bino'][Full.sujet==s].values.tolist())\n",
    "\n",
    "    r_va[s], r_bet[s] = [], []\n",
    "    for c in range(0, 3*200-50, 50) : r_va[s].append([]) ; r_bet[s].append([])\n",
    "\n",
    "    for h in list_h :\n",
    "\n",
    "        for d, c in enumerate(range(0, 3*200-50, 50)) :\n",
    "            x_100 = x[c:c+100]\n",
    "            p_hat_100 = np.zeros(100)\n",
    "\n",
    "            liste = [0, 50, 100]\n",
    "            for a in range(len(liste)-1) :\n",
    "                p_bar, r_bar, beliefs = bcp.inference(x_100[liste[a]:liste[a+1]], h=h, p0=.5, r0=1.)\n",
    "                p_hat_p, r_hat = bcp.readout(p_bar, r_bar, beliefs, mode=modes_bcp, p0=.5, fixed_window_size=40)\n",
    "                p_hat_100[liste[a]:liste[a+1]] = p_hat_p\n",
    "            \n",
    "            r_va[s][d].append(r_(p_hat_100.tolist(), va[c:c+100]))\n",
    "            r_bet[s][d].append(r_(p_hat_100.tolist(), bet[c:c+100]))\n",
    "recording = {}\n",
    "recording['list_h'] = list_h\n",
    "recording['list_tau'] = tau\n",
    "recording['r_va'] = r_va\n",
    "recording['r_bet'] = r_bet\n",
    "\n",
    "file = os.path.join('parametre/list_h', 'list_h_100.pkl')\n",
    "with open(file, 'wb') as fichier:\n",
    "    f = pickle.Pickler(fichier)\n",
    "    f.dump(recording)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Full = e.Full_list(modes_bcp=[])\n",
    "modes_bcp = 'mean'\n",
    "tau = np.arange(1, 601, 1)\n",
    "list_h = 1/tau\n",
    "\n",
    "r_va, r_bet = {}, {}\n",
    "for num, s in enumerate(set(Full.sujet)) :\n",
    "    \n",
    "    print(s, end=' ')\n",
    "    va = Full['va'][Full.sujet==s].values.tolist()\n",
    "    bet = Full['results'][Full.sujet==s].values.tolist()\n",
    "    x = np.array(Full['bino'][Full.sujet==s].values.tolist())\n",
    "\n",
    "    r_va[s], r_bet[s] = [], []\n",
    "    for c in range(0, 3*200-100, 50) : r_va[s].append([]) ; r_bet[s].append([])\n",
    "\n",
    "    for h in list_h :\n",
    "\n",
    "        for d, c in enumerate(range(0, 3*200-100, 50)) :\n",
    "            x_150 = x[c:c+150]\n",
    "            p_hat_150 = np.zeros(150)\n",
    "\n",
    "            liste = [0, 50, 100, 150]\n",
    "            for a in range(len(liste)-1) :\n",
    "                p_bar, r_bar, beliefs = bcp.inference(x_150[liste[a]:liste[a+1]], h=h, p0=.5, r0=1.)\n",
    "                p_hat_p, r_hat = bcp.readout(p_bar, r_bar, beliefs, mode=modes_bcp, p0=.5, fixed_window_size=40)\n",
    "                p_hat_150[liste[a]:liste[a+1]] = p_hat_p\n",
    "            \n",
    "            r_va[s][d].append(r_(p_hat_150.tolist(), va[c:c+150]))\n",
    "            r_bet[s][d].append(r_(p_hat_150.tolist(), bet[c:c+150]))\n",
    "recording = {}\n",
    "recording['list_h'] = list_h\n",
    "recording['list_tau'] = tau\n",
    "recording['r_va'] = r_va\n",
    "recording['r_bet'] = r_bet\n",
    "\n",
    "file = os.path.join('parametre/list_h', 'list_h_150.pkl')\n",
    "with open(file, 'wb') as fichier:\n",
    "    f = pickle.Pickler(fichier)\n",
    "    f.dump(recording)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Full = e.Full_list(modes_bcp=[])\n",
    "modes_bcp = 'mean'\n",
    "tau = np.arange(1, 601, 1)\n",
    "list_h = 1/tau\n",
    "\n",
    "r_va, r_bet = {}, {}\n",
    "for num, s in enumerate(set(Full.sujet)) :\n",
    "    \n",
    "    print(s, end=' ')\n",
    "    va = Full['va'][Full.sujet==s].values.tolist()\n",
    "    bet = Full['results'][Full.sujet==s].values.tolist()\n",
    "    x = np.array(Full['bino'][Full.sujet==s].values.tolist())\n",
    "\n",
    "    r_va[s], r_bet[s] = [], []\n",
    "    for c in range(0, 3*200-150, 50) : r_va[s].append([]) ; r_bet[s].append([])\n",
    "\n",
    "    for h in list_h :\n",
    "\n",
    "        for d, c in enumerate(range(0, 3*200-150, 50)) :\n",
    "            x_200 = x[c:c+200]\n",
    "            p_hat_200 = np.zeros(200)\n",
    "\n",
    "            liste = [0, 50, 100, 150, 200]\n",
    "            for a in range(len(liste)-1) :\n",
    "                p_bar, r_bar, beliefs = bcp.inference(x_200[liste[a]:liste[a+1]], h=h, p0=.5, r0=1.)\n",
    "                p_hat_p, r_hat = bcp.readout(p_bar, r_bar, beliefs, mode=modes_bcp, p0=.5, fixed_window_size=40)\n",
    "                p_hat_200[liste[a]:liste[a+1]] = p_hat_p\n",
    "            \n",
    "            r_va[s][d].append(r_(p_hat_200.tolist(), va[c:c+200]))\n",
    "            r_bet[s][d].append(r_(p_hat_200.tolist(), bet[c:c+200]))\n",
    "recording = {}\n",
    "recording['list_h'] = list_h\n",
    "recording['list_tau'] = tau\n",
    "recording['r_va'] = r_va\n",
    "recording['r_bet'] = r_bet\n",
    "\n",
    "file = os.path.join('parametre/list_h', 'list_h_200.pkl')\n",
    "with open(file, 'wb') as fichier:\n",
    "    f = pickle.Pickler(fichier)\n",
    "    f.dump(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
